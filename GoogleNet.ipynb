{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430537d0-2aa4-4c61-8273-19ec9f9a58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization,GlobalAveragePooling2D, Input, AveragePooling2D, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83821630-ef5c-43f0-9d5f-5e0c69e1f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "TRAIN_DIR = 'D:/Dataset/my - Copy/train'\n",
    "VAL_DIR = 'D:/Dataset/my - Copy/validation'\n",
    "TEST_DIR = 'D:/Dataset/my - Copy/validation'\n",
    "\n",
    "# Define constants\n",
    "IMAGE_WIDTH = int(input(\"Enter image width: \"))\n",
    "IMAGE_HEIGHT = int(input(\"Enter image height: \"))\n",
    "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "BATCH_SIZE = int(input(\"Enter batch size: \"))\n",
    "NUM_EPOCHS = int(input(\"Enter number of epochs: \"))\n",
    "NUM_CLASSES = int(input(\"Enter number of classes: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f2664-3b59-4cd1-91c2-c0f627759256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473a5e3-b671-49de-9571-f2ea1518c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(x,\n",
    "              filters_1x1,\n",
    "              filters_3x3_reduce,\n",
    "              filters_3x3,\n",
    "              filters_5x5_reduce,\n",
    "              filters_5x5,\n",
    "              filters_pool):\n",
    "  path1 = layers.Conv2D(filters_1x1, (1, 1), padding='same',    activation='relu')(x)\n",
    "  path2 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "  path2 = layers.Conv2D(filters_3x3, (1, 1), padding='same', activation='relu')(path2)\n",
    "  path3 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "  path3 = layers.Conv2D(filters_5x5, (1, 1), padding='same', activation='relu')(path3)\n",
    "  path4 = layers.MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "  path4 = layers.Conv2D(filters_pool, (1, 1), padding='same', activation='relu')(path4)\n",
    "  return tf.concat([path1, path2, path3, path4], axis=3)\n",
    "\n",
    "def GoogLeNet():\n",
    "    input_layer = Input(shape=(224, 224, 3))\n",
    "\n",
    "    x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(input_layer)\n",
    "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "    x = layers.Conv2D(64, 1, strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(192, 3, strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "    x = inception(x, filters_1x1=64, filters_3x3_reduce=96, filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool=32)\n",
    "    x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool=64)\n",
    "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "    x = inception(x, filters_1x1=192, filters_3x3_reduce=96, filters_3x3=208, filters_5x5_reduce=16, filters_5x5=48, filters_pool=64)\n",
    "    aux1 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
    "    aux1 =layers.Conv2D(128, 1, padding='same', activation='relu')(aux1)\n",
    "    aux1 = layers.Flatten()(aux1)\n",
    "    aux1 = layers.Dense(1024, activation='relu')(aux1)\n",
    "    aux1 = layers.Dropout(0.7)(aux1)\n",
    "    aux1 = layers.Dense(10, activation='softmax')(aux1)\n",
    "    x = inception(x, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
    "    x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=256, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
    "    x = inception(x, filters_1x1=112, filters_3x3_reduce=144, filters_3x3=288, filters_5x5_reduce=32, filters_5x5=64, filters_pool=64)\n",
    "    aux2 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
    "    aux2 =layers.Conv2D(128, 1, padding='same', activation='relu')(aux2)\n",
    "    aux2 = layers.Flatten()(aux2)\n",
    "    aux2 = layers.Dense(1024, activation='relu')(aux2)\n",
    "    aux2 = layers.Dropout(0.7)(aux2) \n",
    "    aux2 = layers.Dense(10, activation='softmax')(aux2)\n",
    "    x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
    "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "    x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
    "    x = inception(x, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384, filters_5x5_reduce=48, filters_5x5=128, filters_pool=128)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    output_layer = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(input_layer, output_layer, name='GoogLeNet')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = GoogLeNet()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fba5bd-551d-4b8e-8630-cea8509526a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa832db3-0feb-4cc5-8d1f-d9c30a2d3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=val_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc4bb1-0ad3-4978-b552-bc0cc607cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
